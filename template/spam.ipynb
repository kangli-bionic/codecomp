{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset -sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    with open(\"g0\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "else:\n",
    "    sys.stdin.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = [int(x) for x in lines[0].split()]\n",
    "train_data = []\n",
    "for line in lines[1:n+1]:\n",
    "    lst = [list(map(int,x.split(\":\"))) for x in line.split()]\n",
    "    train_data.append([[x[0] for x in lst], [x[1] for x in lst]])\n",
    "targets = []\n",
    "for line in lines[n+1:n+1+n]:\n",
    "    targets.append(int(line))\n",
    "test_data = []\n",
    "for line in lines[n+1+n:n+1+n+m]:\n",
    "    lst = [list(map(int,x.split(\":\"))) for x in line.split()]\n",
    "    test_data.append([[x[0] for x in lst], [x[1] for x in lst]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataset):\n",
    "    processed = []\n",
    "    for loc,time in dataset:\n",
    "        time = [0] + [b-a for a,b in zip(time, time[1:])]*200  # take time diff and cycle\n",
    "        time = time[:200]\n",
    "        loc = loc*200  # cycle locations\n",
    "        loc = loc[:200]\n",
    "        processed.append(time + loc)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_p = process_data(train_data)\n",
    "test_data_p = process_data(test_data)\n",
    "target_train = np.array(targets)\n",
    "df_train = pd.DataFrame(train_data_p)\n",
    "df_test = pd.DataFrame(test_data_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 400\n",
      "[0, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 17033, 0, 11964, 18432, 15014, 15997, 19877, 12008, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    print(len(train_data_p), len(train_data_p[0]))\n",
    "    print(train_data_p[0])  # 200 indexes and 200 time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = np.array([True if i < len(df_train)*0.2 else False for i in range(len(df_train))])\n",
    "lgb_train = lgb.Dataset(df_train[~eval_set], target_train[~eval_set])\n",
    "lgb_eval = lgb.Dataset(df_train[eval_set], target_train[eval_set], reference=lgb_train)\n",
    "lgb_all = lgb.Dataset(df_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 baseline: 0.34, F1 target: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "if DEBUG:\n",
    "    baseline_f1 = f1_score(target_train[eval_set], [1]*len(target_train[eval_set]))\n",
    "    print(\"F1 baseline: {:.2f}, F1 target: {:.2f}\".format(baseline_f1, baseline_f1*1.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[1]\tvalid_0's binary_logloss: 0.452532\tvalid_0's f1: 0\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.413218\tvalid_0's f1: 0\n",
      "[3]\tvalid_0's binary_logloss: 0.382345\tvalid_0's f1: 0\n",
      "[4]\tvalid_0's binary_logloss: 0.357674\tvalid_0's f1: 0\n",
      "[5]\tvalid_0's binary_logloss: 0.336086\tvalid_0's f1: 0.461538\n",
      "[6]\tvalid_0's binary_logloss: 0.319166\tvalid_0's f1: 0.517766\n",
      "[7]\tvalid_0's binary_logloss: 0.303869\tvalid_0's f1: 0.570743\n",
      "[8]\tvalid_0's binary_logloss: 0.290569\tvalid_0's f1: 0.591549\n",
      "[9]\tvalid_0's binary_logloss: 0.279109\tvalid_0's f1: 0.617849\n",
      "[10]\tvalid_0's binary_logloss: 0.269669\tvalid_0's f1: 0.643016\n",
      "[11]\tvalid_0's binary_logloss: 0.260966\tvalid_0's f1: 0.656455\n",
      "[12]\tvalid_0's binary_logloss: 0.254015\tvalid_0's f1: 0.659436\n",
      "[13]\tvalid_0's binary_logloss: 0.247061\tvalid_0's f1: 0.663793\n",
      "[14]\tvalid_0's binary_logloss: 0.241537\tvalid_0's f1: 0.669546\n",
      "[15]\tvalid_0's binary_logloss: 0.236565\tvalid_0's f1: 0.666667\n",
      "[16]\tvalid_0's binary_logloss: 0.232688\tvalid_0's f1: 0.675159\n",
      "[17]\tvalid_0's binary_logloss: 0.228931\tvalid_0's f1: 0.675214\n",
      "[18]\tvalid_0's binary_logloss: 0.224854\tvalid_0's f1: 0.684989\n",
      "[19]\tvalid_0's binary_logloss: 0.221254\tvalid_0's f1: 0.693277\n",
      "[20]\tvalid_0's binary_logloss: 0.217771\tvalid_0's f1: 0.697286\n",
      "[21]\tvalid_0's binary_logloss: 0.214586\tvalid_0's f1: 0.698745\n",
      "[22]\tvalid_0's binary_logloss: 0.212205\tvalid_0's f1: 0.694561\n",
      "[23]\tvalid_0's binary_logloss: 0.209297\tvalid_0's f1: 0.708075\n",
      "[24]\tvalid_0's binary_logloss: 0.206825\tvalid_0's f1: 0.705394\n",
      "[25]\tvalid_0's binary_logloss: 0.20503\tvalid_0's f1: 0.702703\n",
      "[26]\tvalid_0's binary_logloss: 0.202714\tvalid_0's f1: 0.706612\n",
      "[27]\tvalid_0's binary_logloss: 0.201174\tvalid_0's f1: 0.708075\n",
      "[28]\tvalid_0's binary_logloss: 0.199639\tvalid_0's f1: 0.709544\n",
      "[29]\tvalid_0's binary_logloss: 0.198041\tvalid_0's f1: 0.714579\n",
      "[30]\tvalid_0's binary_logloss: 0.196668\tvalid_0's f1: 0.719836\n",
      "[31]\tvalid_0's binary_logloss: 0.195262\tvalid_0's f1: 0.722449\n",
      "[32]\tvalid_0's binary_logloss: 0.1948\tvalid_0's f1: 0.722449\n",
      "[33]\tvalid_0's binary_logloss: 0.19341\tvalid_0's f1: 0.721311\n",
      "[34]\tvalid_0's binary_logloss: 0.192473\tvalid_0's f1: 0.722449\n",
      "[35]\tvalid_0's binary_logloss: 0.191561\tvalid_0's f1: 0.722449\n",
      "[36]\tvalid_0's binary_logloss: 0.190609\tvalid_0's f1: 0.720978\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.195262\tvalid_0's f1: 0.722449\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'verbose': -1 if not DEBUG else 0,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                feval=lgb_f1_score,\n",
    "                valid_sets=lgb_eval,\n",
    "                verbose_eval=DEBUG,\n",
    "                early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = gbm.predict(df_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [int(x > 0.5) for x in pred_test]\n",
    "if not DEBUG:\n",
    "    print(\"\\n\".join(str(x) for x in res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
